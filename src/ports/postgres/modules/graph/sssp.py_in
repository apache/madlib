# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# Single Source Shortest Path

# Please refer to the sssp.sql_in file for the documentation

"""
@file sssp.py_in

@namespace graph
"""

import plpy
from graph_utils import *
from utilities.control import MinWarning
from utilities.utilities import _assert
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import unique_string
from utilities.utilities import _string_to_array
from utilities.utilities import split_quoted_delimited_str
from utilities.validate_args import table_exists
from utilities.validate_args import columns_exist_in_table
from utilities.validate_args import table_is_empty
from utilities.validate_args import get_cols_and_types
from utilities.validate_args import get_expr_type

m4_changequote(`<!', `!>')


def _check_groups(tbl1, tbl2, grp_list):

	"""
	Helper function for joining tables with groups.
	Args:
		@param tbl1       Name of the first table
		@param tbl2       Name of the second table
		@param grp_list   The list of grouping columns
	"""

	sql = []
	for i in grp_list:
		sql.append(" "+tbl1+"."+i+" = "+tbl2+"."+i+" ")
	return " AND ".join(sql)

def _grp_from_table(tbl, grp_list):

	"""
	Helper function for selecting grouping columns of a table
	Args:
		@param tbl        Name of the table
		@param grp_list   The list of grouping columns
	"""

	sql = []
	for i in grp_list:
		sql.append(" "+tbl+"."+i+" ")
	return " , ".join(sql)

def graph_sssp(schema_madlib, vertex_table, vertex_id, edge_table,
		edge_args, source_vertex, out_table, grouping_cols, **kwargs):

	"""
    Single source shortest path function for graphs using the Bellman-Ford
    algorhtm [1].
    Args:
        @param vertex_table     Name of the table that contains the vertex data.
        @param vertex_id        Name of the column containing the vertex ids.
        @param edge_table       Name of the table that contains the edge data.
        @param edge_args        A comma-delimited string containing multiple
                                named arguments of the form "name=value".
        @param source_vertex    The source vertex id for the algorithm to start.
        @param out_table        Name of the table to store the result of SSSP.
        @param grouping_cols    The list of grouping columns.

    [1] https://en.wikipedia.org/wiki/Bellman-Ford_algorithm
    """

	with MinWarning("warning"):

		INT_MAX = 2147483647
		INFINITY = "'Infinity'"
		EPSILON = 0.000001

		message = unique_string(desp='message')

		oldupdate = unique_string(desp='oldupdate')
		newupdate = unique_string(desp='newupdate')

		params_types = {'src': str, 'dest': str, 'weight': str}
		default_args = {'src': 'src', 'dest': 'dest', 'weight': 'weight'}
		edge_params = extract_keyvalue_params(edge_args,
                                            params_types,
                                            default_args)

		# Prepare the input for recording in the summary table
		if vertex_id is None:
			v_st= "NULL"
			vertex_id = "id"
		else:
			v_st = vertex_id
		if edge_args is None:
			e_st = "NULL"
		else:
			e_st = edge_args
		if grouping_cols is None:
			g_st = "NULL"
			glist = None
		else:
			g_st = grouping_cols
			glist = split_quoted_delimited_str(grouping_cols)

		src = edge_params["src"]
		dest = edge_params["dest"]
		weight = edge_params["weight"]

		distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
			<!"DISTRIBUTED BY ({0})".format(vertex_id)!>)
		local_distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
			<!"DISTRIBUTED BY (id)"!>)

		is_hawq = m4_ifdef(<!__HAWQ__!>, <!True!>, <!False!>)
		_validate_sssp(vertex_table, vertex_id, edge_table,
			edge_params, source_vertex, out_table, glist)

		plpy.execute(" DROP TABLE IF EXISTS {0},{1},{2}".format(
			message,oldupdate,newupdate))

		# Initialize grouping related variables
		comma_grp = ""
		comma_grp_e = ""
		comma_grp_m = ""
		grp_comma = ""
		checkg_oo = ""
		checkg_eo = ""
		checkg_ex = ""
		checkg_om = ""
		group_by = ""

		if grouping_cols is not None:
			comma_grp = " , " + grouping_cols
			group_by = " , " + _grp_from_table(edge_table,glist)
			comma_grp_e = " , " + _grp_from_table(edge_table,glist)
			comma_grp_m = " , " + _grp_from_table("message",glist)
			grp_comma = grouping_cols + " , "

			checkg_oo_sub = _check_groups(out_table,"oldupdate",glist)
			checkg_oo = " AND " + checkg_oo_sub
			checkg_eo = " AND " + _check_groups(edge_table,"oldupdate",glist)
			checkg_ex = " AND " + _check_groups(edge_table,"x",glist)
			checkg_om = " AND " + _check_groups("out_table","message",glist)

		w_type = get_expr_type(weight,edge_table).lower()
		init_w = INT_MAX
		if w_type in ['double precision','float8']:
			init_w = INFINITY

		# We keep a table of every vertex, the minimum cost to that destination
		# seen so far and the parent to this vertex in the associated shortest
		# path. This table will be updated throughtout the execution.
		plpy.execute(
			""" CREATE TABLE {out_table} AS ( SELECT
					{grp_comma} {src} AS {vertex_id}, {weight},
					{src} AS parent FROM {edge_table} LIMIT 0)
				{distribution} """.format(**locals()))

		# We keep a summary table to keep track of the parameters used for this
		# SSSP run. This table is used in the path finding function to eliminate
		# the need for repetition.
		plpy.execute( """ CREATE TABLE {out_table}_summary  (
			vertex_table            TEXT,
			vertex_id               TEXT,
			edge_table              TEXT,
			edge_args               TEXT,
			source_vertex           INTEGER,
			out_table               TEXT,
			grouping_cols           TEXT)
			""".format(**locals()))
		plpy.execute( """ INSERT INTO {out_table}_summary VALUES
			('{vertex_table}', '{v_st}', '{edge_table}', '{e_st}',
			{source_vertex}, '{out_table}', '{g_st}')
			""".format(**locals()))

		# We keep 2 update tables and alternate them during the execution.
		# This is necessary since we need to know which vertices are updated in
		# the previous iteration to calculate the next set of updates.
		plpy.execute(
			""" CREATE TEMP TABLE {oldupdate} AS ( SELECT
					{src} AS id, {weight},
					{src} AS parent {comma_grp} FROM {edge_table} LIMIT 0)
				{local_distribution}
				""".format(**locals()))
		plpy.execute(
			""" CREATE TEMP TABLE {newupdate} AS ( SELECT
					{src} AS id, {weight},
					{src} AS parent {comma_grp} FROM {edge_table} LIMIT 0)
				{local_distribution}
				""".format(**locals()))

		# Since HAWQ does not allow us to update, we create a new table and
		# rename at every iteration.
		if is_hawq:
			temp_table = unique_string(desp='temp')
			sql =""" CREATE TABLE {temp_table} AS ( SELECT * FROM {out_table} )
				{distribution} """
			plpy.execute(sql.format(**locals()))

		# GPDB and HAWQ have distributed by clauses to help them with indexing.
		# For Postgres we add the indices manually.
		sql_index = m4_ifdef(<!__POSTGRESQL__!>,
			<!""" CREATE INDEX ON {out_table} ({vertex_id});
				CREATE INDEX ON {oldupdate} (id);
				CREATE INDEX ON {newupdate} (id);
			""".format(**locals())!>,
			<!''!>)
		plpy.execute(sql_index)

		# The initialization step is quite different when grouping is involved
		# since not every group (subgraph) will have the same set of vertices.

		# Example:
		# Assume there are two grouping columns g1 and g2
		# g1 values are 0 or 1. g2 values are 5 or 6
		if grouping_cols is not None:

			# Collate the groups into a single column (string).
			gsql = "::text || ',' || ".join(glist)
			gsql = gsql + "::text "

			# Find every distinct group.
			# Example: This will give us (0,5), (0,6), (1,5) and (1,6)
			groups = plpy.execute(
				"""SELECT array_agg(DISTINCT {gsql}) AS gsql
				FROM {edge_table} """.format(**locals()))[0]['gsql']

			# For each group initialize the output table.
			for i in range(0,len(groups)):
				gslist = []
				gi = groups[i]

				gvals = _string_to_array(gi)

				# Prepare the sql check for a particular group.
				# Example: gcomp will be "g1 = 0 AND g2 = 5"
				for j in range(0,len(glist)):
					gslist.append(glist[j] + " = " + gvals[j])
				gcomp = " AND ".join(gslist)

				# Find the vertices that are involved in this group
				plpy.execute(
					""" INSERT INTO {out_table}
					SELECT DISTINCT ON ({vertex_id})
						{grp_comma} {vertex_id} AS {vertex_id},
						{init_w} AS {weight},
					NULL::INT AS parent
					FROM (
						SELECT {src} AS {vertex_id} {comma_grp}
						FROM {edge_table} WHERE {gcomp}
						UNION
						SELECT {dest} AS {vertex_id} {comma_grp}
						FROM {edge_table} WHERE {gcomp}
						) x
					WHERE {vertex_id} IS NOT NULL
					""".format(**locals()))

				# The source can be reached with 0 cost and
				# it has itself as the parent.
				plpy.execute(
					""" INSERT INTO {oldupdate}
						VALUES({source_vertex},0,{source_vertex},{gi})
					""".format(**locals()))

			# The maximum number of vertices for any group.
			# Used for determining negative cycles.
			v_cnt = plpy.execute(
				""" SELECT max(count) as max FROM (
						SELECT count({vertex_id}) AS count
						FROM {out_table}
						GROUP BY {grouping_cols}) x
				""".format(**locals()))[0]['max']
		else:
			plpy.execute(
				""" INSERT INTO {out_table}
				SELECT {vertex_id} AS {vertex_id},
					{init_w} AS {weight},
					NULL AS parent
				FROM {vertex_table}
				WHERE {vertex_id} IS NOT NULL
				 """.format(**locals()))

			# The source can be reached with 0 cost and it has itself as the parent.
			plpy.execute(
				""" INSERT INTO {oldupdate}
					VALUES({source_vertex},0,{source_vertex})
				""".format(**locals()))

			v_cnt = plpy.execute(
				""" SELECT count(*) FROM {vertex_table}
				WHERE {vertex_id} IS NOT NULL
				""".format(**locals()))[0]['count']

		for i in range(0,v_cnt+1):

			# Apply the updates calculated in the last iteration.
			if is_hawq:
				sql = """
				TRUNCATE TABLE {temp_table};
				INSERT INTO {temp_table}
					SELECT *
					FROM {out_table}
					WHERE NOT EXISTS (
						SELECT 1
						FROM {oldupdate} as oldupdate
						WHERE {out_table}.{vertex_id} = oldupdate.id
						{checkg_oo})
					UNION
					SELECT {grp_comma} id, {weight}, parent FROM {oldupdate};
				DROP TABLE {out_table};
				ALTER TABLE {temp_table} RENAME TO {out_table};
				CREATE TABLE {temp_table} AS (
					SELECT * FROM {out_table} LIMIT 0)
					{distribution};"""
				plpy.execute(sql.format(**locals()))
				ret = plpy.execute("SELECT id FROM {0} LIMIT 1".
					format(oldupdate))
			else:
				sql = """
				UPDATE {out_table} SET
				{weight}=oldupdate.{weight},
				parent=oldupdate.parent
				FROM
				{oldupdate} AS oldupdate
				WHERE
				{out_table}.{vertex_id}=oldupdate.id AND
				{out_table}.{weight}>oldupdate.{weight} {checkg_oo}
				"""
				ret = plpy.execute(sql.format(**locals()))

			if ret.nrows() == 0:
				break

			plpy.execute("TRUNCATE TABLE {0}".format(newupdate))

			# 'oldupdate' table has the update info from the last iteration

			# Consider every edge that has an updated source
			# From these edges:
			# For every destination vertex, find the min total cost to reach.
			# Note that, just calling an aggregate function with group by won't
			# let us store the src field of the edge (needed for the parent).
			# This is why we need the 'x'; it gives a list of destinations and
			# associated min values. Using these values, we identify which edge
			# is selected.

			# Since using '='' with floats is dangerous we use an epsilon value
			# for comparison.

			# Once we have a list of edges and values (stores as 'message'),
			# we check if these values are lower than the existing shortest path
			# values.

			sql = (""" INSERT INTO {newupdate}
				SELECT DISTINCT ON (message.id {comma_grp})
					message.id AS id,
					message.{weight} AS {weight},
					message.parent AS parent {comma_grp_m}
				FROM {out_table} AS out_table INNER JOIN
					(
					SELECT {edge_table}.{dest} AS id, x.{weight} AS {weight},
						oldupdate.id AS parent {comma_grp_e}
					FROM {oldupdate} AS oldupdate INNER JOIN
						{edge_table}  ON
							({edge_table}.{src} = oldupdate.id {checkg_eo})
						INNER JOIN
						(
						SELECT {edge_table}.{dest} AS id,
							min(oldupdate.{weight} +
								{edge_table}.{weight}) AS {weight} {comma_grp_e}
						FROM {oldupdate} AS oldupdate INNER JOIN
							{edge_table}  ON
							({edge_table}.{src}=oldupdate.id {checkg_eo})
						GROUP BY {edge_table}.{dest} {comma_grp_e}
						) x
						ON ({edge_table}.{dest} = x.id {checkg_ex} )
					WHERE ABS(oldupdate.{weight} + {edge_table}.{weight}
								- x.{weight}) < {EPSILON}
					) message
					ON (message.id = out_table.{vertex_id} {checkg_om})
				WHERE message.{weight}<out_table.{weight}
				""".format(**locals()))

			plpy.execute(sql)

			# Swap the update tables for the next iteration.
			tmp = oldupdate
			oldupdate = newupdate
			newupdate = tmp

		# The algorithm should converge in less than |V| iterations.
		# Otherwise there is a negative cycle in the graph.
		if i == v_cnt:
			if grouping_cols is None:
				plpy.execute("DROP TABLE IF EXISTS {out_table}".
					format(**locals()))
				plpy.error("Graph SSSP: Detected a negative cycle in the graph.")

			# It is possible that not all groups has negative cycles.
			else:

				# gsql is the string created by collating grouping columns.
				# By looking at the oldupdate table we can see which groups
				# are in a negative cycle.

				negs = plpy.execute(
					""" SELECT array_agg(DISTINCT {gsql}) AS grp
						FROM {oldupdate}
					""".format(**locals()))[0]['grp']

				# Delete the groups with negative cycles from the output table.
				sql_del = """ DELETE FROM {out_table}
					USING {oldupdate} AS oldupdate
					WHERE {checkg_oo_sub}"""
				if is_hawq:
					sql_del = """
						TRUNCATE TABLE {temp_table};
						INSERT INTO {temp_table}
							SELECT *
							FROM {out_table}
							WHERE NOT EXISTS(
								SELECT 1
								FROM {oldupdate} as oldupdate
								WHERE {checkg_oo_sub}
								);
						DROP TABLE {out_table};
						ALTER TABLE {temp_table} RENAME TO {out_table};"""

				plpy.execute(sql_del.format(**locals()))

				# If every group has a negative cycle,
				# drop the output table as well.
				if table_is_empty(out_table):
					plpy.execute("DROP TABLE IF EXISTS {0},{1}".
						format(out_table,out_table+"_summary"))

				plpy.warning(
					"""Graph SSSP: Detected a negative cycle in the """ +
					"""sub-graphs of following groups: {0}.""".
					format(str(negs)[1:-1]))

		if is_hawq:
			plpy.execute("DROP TABLE IF EXISTS {temp_table} ".
				format(**locals()))

	return None

def _path_helper(plan_name, dest_vertex, path_table, gset):
	"""
	Helper function for graph_sssp_get_path. Invoked once per group.
	@param plan_name    Name of the plan that finds the parent of a given
	                    vertex.
    @param dest_vertex  The vertex that will be the destination of the
                        desired path.
    @param path_table   Name of the output table that will contain the path(s).
    @param gset	        List of grouping columns values followed by a comma.
                        Empty string if there are no grouping columns.
	"""

	ret = [str(dest_vertex)]
	cur = dest_vertex
	sql = "EXECUTE {plan_name} ({cur})"
	parent = plpy.execute(sql.format(**locals()))
	if parent.nrows() > 0:
		while 1:
			parent = parent[0]['parent']
			if parent == cur:
				ret.reverse()
				ret = ",".join(ret)
				plpy.execute(
					""" INSERT INTO {path_table} VALUES ({gset} '{ret}')
					""".format(**locals()))
				return True
			else:
				ret.append(str(parent))
				cur = parent

			parent = plpy.execute(sql.format(**locals()))

	return False

def graph_sssp_get_path(schema_madlib, sssp_table, dest_vertex, path_table,
	**kwargs):
	"""
    Helper function that can be used to get the shortest path for a vertex
    Args:
        @param source_table Name of the table that contains the SSSP output.
        @param out_table    The vertex that will be the destination of the
                            desired path.
        @param path_table   Name of the output table that contains the path.
	"""
	with MinWarning("warning"):

		_validate_get_path(sssp_table, dest_vertex)
		plan_name = unique_string(desp='plan')

		select_grps = ""
		gsql = ""

		path_flag = False

		summary = plpy.execute("SELECT * FROM {0}_summary".format(sssp_table))
		vertex_id = summary[0]['vertex_id']
		if vertex_id == "NULL":
			vertex_id = "id"

		grouping_cols = summary[0]['grouping_cols']
		if grouping_cols != "NULL":
			glist = split_quoted_delimited_str(grouping_cols)
			select_grps = _grp_from_table(sssp_table,glist) + " , "

		plpy.execute("""
			CREATE TABLE {path_table} AS
				SELECT {select_grps} ''::text as path
				FROM {sssp_table}
				LIMIT 0
			""".format(**locals()))

		plan = """ PREPARE {plan_name} (int) AS
			SELECT parent FROM {sssp_table}
			WHERE {vertex_id} = $1 AND parent IS NOT NULL {gsql} LIMIT 1
			"""

		if grouping_cols == "NULL":
			plpy.execute(plan.format(**locals()))
			path_flag = _path_helper(plan_name,dest_vertex,path_table,"")

		else:
			gvalues = plpy.execute(
				""" SELECT {grouping_cols} FROM {sssp_table}
					GROUP BY {grouping_cols}""".format(**locals()))

			for i in gvalues:
				cur = dest_vertex
				gcheck = []
				gset = []
				for j in glist:
					gcheck.append("{0} = {1}".format(j,i[j]))
					gset.append("{0}".format(i[j]))
				gsql = " AND " + " AND ".join(gcheck)
				gset = " , ".join(gset) + " , "

				# Follow the 'parent' chain until you reach the source.
				# We don't need to know what the source is since it is the
				# only vertex with itself as its parent
				plpy.execute(plan.format(**locals()))
				path_flag = path_flag | _path_helper(
					plan_name,dest_vertex,path_table,gset)

				plpy.execute("DEALLOCATE {0}".format(plan_name))

		if path_flag is False:
			plpy.execute("DROP TABLE IF EXISTS {0}".format(path_table))
			plpy.error(
				"Graph SSSP: Vertex {0} is not present in the sssp table {1}".
				format(dest_vertex,sssp_table))

	return None

def _validate_sssp(vertex_table, vertex_id, edge_table, edge_params,
	source_vertex, out_table, glist, **kwargs):

	validate_graph_coding(vertex_table, vertex_id, edge_table, edge_params,
		out_table,'SSSP')

	_assert(isinstance(source_vertex,int),
		"""Graph SSSP: Source vertex {source_vertex} has to be an integer.""".
		format(**locals()))
	src_exists = plpy.execute("""
		SELECT * FROM {vertex_table} WHERE {vertex_id}={source_vertex}
		""".format(**locals()))

	if src_exists.nrows() == 0:
		plpy.error(
			"""Graph SSSP: Source vertex {source_vertex} is not present in the vertex table {vertex_table}.""".
			format(**locals()))

	vt_error = plpy.execute(
		""" SELECT {vertex_id}
			FROM {vertex_table}
			WHERE {vertex_id} IS NOT NULL
			GROUP BY {vertex_id}
			HAVING count(*) > 1 """.format(**locals()))

	if vt_error.nrows() != 0:
		plpy.error(
			"""Graph SSSP: Source vertex table {vertex_table} contains duplicate vertex id's.""".
			format(**locals()))

	_assert(not table_exists(out_table+"_summary"),
		"Graph SSSP: Output summary table already exists!".format(**locals()))

	if glist is not None:
		_assert(columns_exist_in_table(edge_table, glist),
			"""Graph SSSP: Not all columns from {glist} are present in edge table ({edge_table}).""".
			format(**locals()))

	return None

def _validate_get_path(sssp_table, dest_vertex, **kwargs):

	_assert(sssp_table and sssp_table.strip().lower() not in ('null', ''),
		"Graph SSSP: Invalid SSSP table name!")
	_assert(table_exists(sssp_table),
		"Graph SSSP: SSSP table ({0}) is missing!".format(sssp_table))
	_assert(not table_is_empty(sssp_table),
		"Graph SSSP: SSSP table ({0}) is empty!".format(sssp_table))

	summary = sssp_table+"_summary"
	_assert(table_exists(summary),
		"Graph SSSP: SSSP summary table ({0}) is missing!".format(summary))
	_assert(not table_is_empty(summary),
		"Graph SSSP: SSSP summary table ({0}) is empty!".format(summary))

	return None


def graph_sssp_help(schema_madlib, message, **kwargs):
	"""
	Help function for graph_sssp and graph_sssp_get_path

	Args:
		@param schema_madlib
		@param message: string, Help message string
		@param kwargs

	Returns:
	    String. Help/usage information
	"""
	if not message:
		help_string = """
-----------------------------------------------------------------------
                            SUMMARY
-----------------------------------------------------------------------

Given a graph and a source vertex, single source shortest path (SSSP)
algorithm finds a path for every vertex such that the the sum of the
weights of its constituent edges is minimized.

For more details on function usage:
    SELECT {schema_madlib}.graph_sssp('usage')
            """
	elif message.lower() in ['usage', 'help', '?']:
		help_string = """
{graph_usage}

To retrieve the path for a specific vertex:

 SELECT {schema_madlib}.graph_sssp_get_path(
    sssp_table	TEXT, -- Name of the table that contains the SSSP output.
    dest_vertex	INT,  -- The vertex that will be the destination of the
                      -- desired path.
    path_table  TEXT  -- Name of the output table that contains the path.
);

----------------------------------------------------------------------------
                            OUTPUT
----------------------------------------------------------------------------
The output table ('out_table' above) will contain a row for every vertex from
vertex_table and have the following columns:

vertex_id 	: The id for the destination. Will use the input parameter
		(vertex_id) for column naming.
weight 		: The total weight of the shortest path from the source vertex
		to this particular vertex. Will use the input parameter (weight)
		for column naming.
parent 		: The parent of this vertex in the shortest path from source.
		Will use "parent" for column naming.

# The graph_sssp_get_path function will return an INT array that contains the
# shortest path from the initial source vertex to the desired destination vertex.
# """
	elif message.lower() in ("example", "examples"):
		help_string = """
----------------------------------------------------------------------------
                                EXAMPLES
----------------------------------------------------------------------------
-- Create a graph, represented as vertex and edge tables.
DROP TABLE IF EXISTS vertex,edge,out,out_summary,out_path;
CREATE TABLE vertex(
        id INTEGER
        );
CREATE TABLE edge(
        src INTEGER,
        dest INTEGER,
        weight DOUBLE PRECISION
);

INSERT INTO vertex VALUES
(0),
(1),
(2),
(3),
(4),
(5),
(6),
(7)
;
INSERT INTO edge VALUES
(0, 1, 1),
(0, 2, 1),
(0, 4, 10),
(1, 2, 2),
(1, 3, 10),
(2, 3, 1),
(2, 5, 1),
(2, 6, 3),
(3, 0, 1),
(4, 0, -2),
(5, 6, 1),
(6, 7, 1)
;

-- Compute the SSSP:
DROP TABLE IF EXISTS pagerank_out;
SELECT madlib.graph_sssp(
	'vertex',                            -- Vertex table
	'id',                                -- Vertix id column
	'edge',                              -- Edge table
	'src=src, dest=dest, weight=weight', -- Comma delimted string of edge arguments
	 0,                                  -- The source vertex
	'out'                                -- Output table of SSSP
);
-- View the SSSP costs for every vertex:
SELECT * FROM out ORDER BY id;

-- View the actual shortest path for a vertex:
SELECT graph_sssp_get_path('out',5,'out_path');
SELECT * FROM out_path;
"""
	else:
		help_string = "No such option. Use {schema_madlib}.graph_sssp()"

	return help_string.format(schema_madlib=schema_madlib,
		graph_usage=get_graph_usage(schema_madlib, 'graph_sssp',
    """source_vertex INT,  -- The source vertex id for the algorithm to start.
    out_table     TEXT  -- Name of the table to store the result of SSSP.
    grouping_cols TEXT  -- The list of grouping columns."""))
# ---------------------------------------------------------------------
