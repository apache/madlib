# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import numpy as np
import os
import plpy

# Import needed for get_data_as_np_array()
from keras import utils as keras_utils

#######################################################################
########### Helper functions to serialize and deserialize weights #####
#######################################################################
class KerasWeightsSerializer:

    @staticmethod
    def get_model_shapes(model):
        model_shapes = []
        for a in model.get_weights():
            model_shapes.append(a.shape)
        return model_shapes

    @staticmethod
    def deserialize_weights(model_state, model_shapes):
        """
        Parameters:
            model_state: a stringified (serialized) state containing loss,
            accuracy, buffer_count, and model_weights, passed from postgres
            model_shapes: a list of tuples containing the shapes of each element
            in keras.get_weights()
        Returns:
            buffer_count: the buffer count from state
            model_weights: a list of numpy arrays that can be inputted into keras.set_weights()
        """
        if not model_state or not model_shapes:
            return None
        state = np.fromstring(model_state, dtype=np.float32)
        model_weights_serialized = state[3:]
        i, j, model_weights = 0, 0, []
        while j < len(model_shapes):
            next_pointer = i + reduce(lambda x, y: x * y, model_shapes[j])
            weight_arr_portion = model_weights_serialized[i:next_pointer]
            model_weights.append(weight_arr_portion.reshape(model_shapes[j]))
            i, j = next_pointer, j + 1
        return int(float(state[0])), int(float(state[1])), int(float(state[2])), model_weights

    @staticmethod
    def serialize_weights(loss, accuracy, buffer_count, model_weights):
        """
        Parameters:
            loss, accuracy, buffer_count: float values
            model_weights: a list of numpy arrays, what you get from
            keras.get_weights()
        Returns:
            A stringified (serialized) state containing all these values, to be
            passed to postgres
        """
        if model_weights is None:
            return None
        flattened_weights = [w.flatten() for w in model_weights]
        model_weights_serialized = np.concatenate(flattened_weights)
        new_model_string = np.array([loss, accuracy, buffer_count])
        new_model_string = np.concatenate((new_model_string, model_weights_serialized))
        new_model_string = np.float32(new_model_string)
        return new_model_string.tostring()

    @staticmethod
    def deserialize_iteration_state(iteration_result):
        """
        Parameters:
            iteration_result: the output of the step function
        Returns:
            loss: the averaged loss from that iteration of training
            accuracy: the averaged accuracy from that iteration of training
            new_model_state: the stringified (serialized) state to pass in to next
            iteration of step function training, represents the averaged weights
            from the last iteration of training; zeros out loss, accuracy,
            buffer_count in this state because the new iteration must start with
            fresh values
        """
        if not iteration_result:
            return None
        state = np.fromstring(iteration_result, dtype=np.float32)
        new_model_string = np.array(state)
        new_model_string[0], new_model_string[1], new_model_string[2] = 0, 0, 0
        new_model_string = np.float32(new_model_string)
        return float(state[0]), float(state[1]), new_model_string.tostring()

    @staticmethod
    def deserialize_weights_merge(state):
        """
        Parameters:
            state: the stringified (serialized) state containing loss, accuracy, buffer_count, and
                model_weights, passed from postgres to merge function
        Returns:
            loss: the averaged loss from that iteration of training
            accuracy: the averaged accuracy from that iteration of training
            buffer_count: total buffer counts processed
            model_weights: a single flattened numpy array containing all of the
            weights, flattened because all we have to do is average them (so don't
            have to reshape)
        """
        if not state:
            return None
        state = np.fromstring(state, dtype=np.float32)
        return float(state[0]), float(state[1]), int(float(state[2])), state[3:]

    @staticmethod
    def serialize_weights_merge(loss, accuracy, buffer_count, model_weights):
        """
        Parameters:
            loss, accuracy, buffer_count: float values
            model_weights: a single flattened numpy array containing all of the
            weights, averaged in merge function over the 2 states
        Returns:
            A stringified (serialized) state containing all these values, to be
            passed to postgres
        """
        if model_weights is None:
            return None
        new_model_string = np.array([loss, accuracy, buffer_count])
        new_model_string = np.concatenate((new_model_string, model_weights))
        new_model_string = np.float32(new_model_string)
        return new_model_string.tostring()

    @staticmethod
    def deserialize_weights_orig(model_weights_serialized, model_shapes):
        """
        Original deserialization for warm-start, used only to parse model received
        from query at the top of this file
        """
        i, j, model_weights = 0, 0, []
        while j < len(model_shapes):
            next_pointer = i + reduce(lambda x, y: x * y, model_shapes[j])
            weight_arr_portion = model_weights_serialized[i:next_pointer]
            model_weights.append(np.array(weight_arr_portion).reshape(model_shapes[j]))
            i, j = next_pointer, j + 1
        return model_weights


#######################################################################
########### General Helper functions  #######
#######################################################################

def get_data_as_np_array(table_name, y, x, input_shape, num_classes):
    """

    :param table_name: Table containing the batch of images per row
    :param y: Column name for y
    :param x: Column name for x
    :param input_shape: input_shape of data in array format [L , W , C]
    :param num_classes: num of distinct classes in y
    :return:
    """
    val_data_qry = "SELECT {0}, {1} FROM {2}".format(y, x, table_name)
    input_shape = map(int, input_shape)
    val_data = plpy.execute(val_data_qry)
    indep_len = len(val_data[0][x])
    pixels_per_image = int(input_shape[0] * input_shape[1] * input_shape[2])
    x_validation = np.ndarray((0,indep_len, pixels_per_image))
    y_validation = np.ndarray((0,indep_len))
    for i in range(len(val_data)):
        x_test = np.asarray((val_data[i][x],))
        x_test = x_test.reshape(1, indep_len, pixels_per_image)
        y_test = np.asarray((val_data[i][y],))
        y_test = y_test.reshape(1, indep_len)
        x_validation=np.concatenate((x_validation, x_test))
        y_validation=np.concatenate((y_validation, y_test))
    num_test_examples = x_validation.shape[0]
    x_validation = x_validation.reshape(indep_len * num_test_examples, *input_shape)
    x_validation = x_validation.astype('float64')
    y_validation = y_validation.reshape(indep_len * num_test_examples)

    x_validation = x_validation.astype('float64')
    #x_validation /= 255.0
    y_validation = keras_utils.to_categorical(y_validation, num_classes)

    return x_validation, y_validation
