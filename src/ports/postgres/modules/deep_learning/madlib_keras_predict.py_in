# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import plpy
import os

import keras
from keras import backend as K
from keras.layers import *
from keras.models import *
from keras.optimizers import *

from madlib_keras_helper import expand_input_dims
from madlib_keras_helper import strip_trailing_nulls_from_class_values
from madlib_keras_validator import PredictInputValidator
from predict_input_params import PredictParamsProcessor
from utilities.control import MinWarning
from utilities.model_arch_info import get_input_shape
from utilities.utilities import add_postfix
from utilities.utilities import create_cols_from_array_sql_string
from utilities.utilities import get_segments_per_host
from utilities.utilities import is_platform_pg
from utilities.utilities import unique_string

from madlib_keras_wrapper import *

MODULE_NAME = 'madlib_keras_predict'

@MinWarning("warning")
def predict(schema_madlib, model_table, test_table, id_col,
            independent_varname, output_table, pred_type, gpus_per_host, **kwargs):
    if not pred_type:
        pred_type = 'response'
    input_validator = PredictInputValidator(
        test_table, model_table, id_col, independent_varname,
        output_table, pred_type, MODULE_NAME)

    param_proc = PredictParamsProcessor(model_table, MODULE_NAME)
    class_values = param_proc.get_class_values()
    input_validator.validate_pred_type(class_values)
    dependent_varname = param_proc.get_dependent_varname()
    dependent_vartype = param_proc.get_dependent_vartype()
    model_data = param_proc.get_model_data()
    model_arch = param_proc.get_model_arch()
    normalizing_const = param_proc.get_normalizing_const()
    input_shape = get_input_shape(model_arch)
    input_validator.validate_input_shape(input_shape)

    is_response = True if pred_type == 'response' else False
    intermediate_col = unique_string()
    if is_response:
        pred_col_name = add_postfix("estimated_", dependent_varname)
        pred_col_type = dependent_vartype
    else:
        pred_col_name = "prob"
        pred_col_type = 'double precision'

    class_values = strip_trailing_nulls_from_class_values(class_values)

    prediction_select_clause = create_cols_from_array_sql_string(
        class_values, intermediate_col, pred_col_name,
        pred_col_type, is_response, MODULE_NAME)

    gp_segment_id_col, seg_ids_test, \
    images_per_seg_test = get_images_per_seg_for_non_minibatched_data(test_table)
    segments_per_host = get_segments_per_host()

    if is_platform_pg():
        set_keras_session(gpus_per_host, segments_per_host)
    else:
        # we want to disable gpu on gpdb's master node because GPUs will only be used
        # for segment nodes.
        set_cuda_env('-1')

    predict_query = plpy.prepare("""
        CREATE TABLE {output_table} AS
        SELECT {id_col}, {prediction_select_clause}
        FROM (
            SELECT {test_table}.{id_col},
                   ({schema_madlib}.internal_keras_predict
                       ({independent_varname},
                        $1,
                        $2,
                        {is_response},
                        {normalizing_const},
                        {gp_segment_id_col},
                        ARRAY{seg_ids_test},
                        ARRAY{images_per_seg_test},
                        {gpus_per_host},
                        {segments_per_host})
                   ) AS {intermediate_col}
        FROM {test_table}
        ) q
        """.format(**locals()), ["text", "bytea"])
    plpy.execute(predict_query, [model_arch, model_data])

    if is_platform_pg():
        clear_keras_session()

def get_images_per_seg_for_non_minibatched_data(table_name):
    """
    This function queries the given table and returns the total rows per segment.
    Since we cannot pass a dictionary to the keras fit step function we create arrays
    out of the segment numbers and the rows per segment values.
    This function assumes that the table is not empty.
    :param table_name:
    :return: gp segment id col name and two arrays
    1. An array containing all the segment numbers in ascending order
    2. An array containing the total rows for each of the segments in the
    segment array
    """
    if is_platform_pg():
        images_per_seg = plpy.execute(
            """ SELECT count(*) AS images_per_seg
                FROM {0}
            """.format(table_name))
        seg_ids = [0]
        gp_segment_id_col = '0'
    else:
        # Compute total buffers on each segment
        images_per_seg = plpy.execute(
            """ SELECT gp_segment_id, count(*) AS images_per_seg
                FROM {0}
                GROUP BY gp_segment_id
            """.format(table_name))
        seg_ids = [int(image["gp_segment_id"]) for image in images_per_seg]
        gp_segment_id_col = '{0}.gp_segment_id'.format(table_name)

    images_per_seg = [int(image["images_per_seg"]) for image in images_per_seg]
    return gp_segment_id_col, seg_ids, images_per_seg

def internal_keras_predict(independent_var, model_architecture, model_data,
                           is_response, normalizing_const, current_seg_id, seg_ids,
                           images_per_seg, gpus_per_host, segments_per_host,
                           **kwargs):
    SD = kwargs['SD']
    model_key = 'segment_model_predict'
    row_count_key = 'row_count'
    try:
        device_name = get_device_name_and_set_cuda_env(gpus_per_host,
                                                       current_seg_id)
        if model_key not in SD:
            if not is_platform_pg():
                set_keras_session(gpus_per_host, segments_per_host)
            model = model_from_json(model_architecture)
            model_shapes = get_model_shapes(model)
            set_model_weights(model, device_name, model_data, model_shapes)

            SD[model_key] = model
            SD[row_count_key] = 0
        else:
            model = SD[model_key]
        SD[row_count_key] += 1

        # Since the test data isn't mini-batched,
        # we have to make sure that the test data np array has the same
        # number of dimensions as input_shape. So we add a dimension to x.
        independent_var = expand_input_dims(independent_var, target_type='float32')
        independent_var /= normalizing_const

        if is_response:
            with K.tf.device(device_name):
                y_prob = model.predict(independent_var)
                proba_argmax = y_prob.argmax(axis=-1)
            # proba_argmax is a list with exactly one element in it. That element
            # refers to the index containing the largest probability value in the
            # output of Keras' predict function.
            result = proba_argmax
        else:
            with K.tf.device(device_name):
                probs = model.predict(independent_var)
            # probs is a list containing a list of probability values, of all
            # class levels. Since we are assuming each input is a single image,
            # and not mini-batched, this list contains exactly one list in it,
            # so return back the first list in probs.
            result = probs[0]

        if is_platform_pg():
            total_images = images_per_seg[0]
        else:
            total_images = images_per_seg[seg_ids.index(current_seg_id)]

        if SD[row_count_key] == total_images:
            SD.pop(model_key, None)
            SD.pop(row_count_key, None)
            if not is_platform_pg():
                clear_keras_session()
        return result
    except Exception as ex:
        SD.pop(model_key, None)
        SD.pop(row_count_key, None)
        if not is_platform_pg():
            clear_keras_session()
        plpy.error(ex)
