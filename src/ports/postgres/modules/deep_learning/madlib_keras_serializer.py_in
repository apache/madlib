# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import numpy as np

def get_model_shapes(model):
    model_shapes = []
    for a in model.get_weights():
        model_shapes.append(a.shape)
    return model_shapes

# TODO
# Current serializing logic
# serialized string -> byte string
# np.array(np.array(loss, acc, buff_count).concatenate(weights_np_array)).tostring()

# Proposed logic
# loss , accuracy and image_count can be comma separated values
# weights -> np.array.tostring()
# combine these 2 into one string by a random splitter
# serialized string -> loss_splitter_acc_splitter_buffer_splitter_weights

def deserialize_weights(model_state, model_shapes):
    """
    Parameters:
        model_state: a stringified (serialized) state containing
        image_count and model_weights, passed from postgres
        model_shapes: a list of tuples containing the shapes of
        each element in keras.get_weights()
    Returns:
        image_count: the buffer count from state
        model_weights: a list of numpy arrays that can be inputted into keras.set_weights()
    """
    if not model_state or not model_shapes:
        return None
    state = np.fromstring(model_state, dtype=np.float32)

    model_weights_serialized = state[1:]
    i, j, model_weights = 0, 0, []
    while j < len(model_shapes):
        next_pointer = i + reduce(lambda x, y: x * y, model_shapes[j])
        weight_arr_portion = model_weights_serialized[i:next_pointer]
        model_weights.append(weight_arr_portion.reshape(model_shapes[j]))
        i, j = next_pointer, j + 1
    #TODO: float(state[0]) is the image_count, which can be get from
    # get_image_count_from_state() we defined below, we should check if
    # we still need to return it here when refactoring
    return float(state[0]), model_weights

def get_image_count_from_state(model_state):
    if not model_state:
        return None
    state = np.fromstring(model_state, dtype=np.float32)
    return float(state[0])

def serialize_weights(image_count, model_weights):
    """
    Parameters:
        image_count: float values
        model_weights: a list of numpy arrays, what you get from
        keras.get_weights()
    Returns:
        A stringified (serialized) state containing all these values, to be
        passed to postgres
    """
    if model_weights is None:
        return None
    flattened_weights = [w.flatten() for w in model_weights]
    model_weights_serialized = np.concatenate(flattened_weights)
    new_model_string = np.array([image_count])
    new_model_string = np.concatenate((new_model_string, model_weights_serialized))
    new_model_string = np.float32(new_model_string)
    return new_model_string.tostring()

def deserialize_iteration_state(iteration_result):
    """
    Parameters:
        iteration_result: the output of the step function
    Returns:
        new_model_state: the stringified (serialized) state to pass in to next
        iteration of step function training, represents the averaged weights
        from the last iteration of training; zeros out image_count in this state
        because the new iteration must start with
        fresh values
    """
    if not iteration_result:
        return None
    state = np.fromstring(iteration_result, dtype=np.float32)
    new_model_string = np.array(state)
    new_model_string[0]= 0
    new_model_string = np.float32(new_model_string)
    return new_model_string.tostring()


def deserialize_weights_merge(state):
    """
    Parameters:
        state: the stringified (serialized) state containing loss, accuracy, image_count, and
            model_weights, passed from postgres to merge function
    Returns:
        image_count: total buffer counts processed
        model_weights: a single flattened numpy array containing all of the
        weights, flattened because all we have to do is average them (so don't
        have to reshape)
    """
    if not state:
        return None
    state = np.fromstring(state, dtype=np.float32)
    return float(state[0]), state[1:]


def serialize_weights_merge(image_count, model_weights):
    """
    Parameters:
        image_count: float values
        model_weights: a single flattened numpy array containing all of the
        weights, averaged in merge function over the 2 states
    Returns:
        A stringified (serialized) state containing all these values, to be
        passed to postgres
    """
    if model_weights is None:
        return None
    new_model_string = np.array([image_count])
    new_model_string = np.concatenate((new_model_string, model_weights))
    new_model_string = np.float32(new_model_string)
    return new_model_string.tostring()


def deserialize_weights_orig(model_weights_serialized, model_shapes):
    """
    Original deserialization for warm-start, used only to parse model received
    from query at the top of this file
    """
    i, j, model_weights = 0, 0, []
    while j < len(model_shapes):
        next_pointer = i + reduce(lambda x, y: x * y, model_shapes[j])
        weight_arr_portion = model_weights_serialized[i:next_pointer]
        model_weights.append(np.array(weight_arr_portion).reshape(model_shapes[j]))
        i, j = next_pointer, j + 1
    return model_weights
